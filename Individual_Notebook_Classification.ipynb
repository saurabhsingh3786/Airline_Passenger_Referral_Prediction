{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "xFWQlqiZzWhk",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "78s0tPeSfdtf",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "qswI8AS8Aqz6",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "iqYeVgh1lSJz",
        "S9OmyMoblSJ3",
        "e6OpR3aylSJ-",
        "4nL01t96lSKA",
        "6zhf4ZkB1_OX",
        "zjkIOGzd1_Oh",
        "3Nl7Eb7T1_Oi",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saurabhsingh3786/Airline_Passenger_Referral_Prediction/blob/main/Individual_Notebook_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - `Airline Passenger Referral Prediction`\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual(Saurabh Singh)\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customer referral is a crucial aspect of business growth and success, and the airline industry is no exception. Satisfied passengers who have had positive experiences with an airline are more likely to refer the airline to their friends, family, and colleagues. Identifying these potential advocates can help airlines improve customer satisfaction and loyalty and attract new customers.\n",
        "\n",
        "In this project, we will use machine learning algorithms to predict whether a passenger will refer an airline to others. We will use a dataset that includes past passengers and their referral behavior, as well as various features such as age, gender, flight class, and route information.\n",
        "\n",
        "Our first step will be to perform exploratory data analysis to gain insights into the data and identify any patterns or correlations. We will then preprocess the data by handling missing values, encoding categorical variables, and scaling numeric features.\n",
        "\n",
        "We will then apply several machine learning algorithms, including logistic regression, random forest, and support vector machines, to predict the likelihood of a passenger becoming a referral. We will also perform feature engineering and selection to improve the performance of our models.\n",
        "\n",
        "Finally, we will evaluate our models using metrics such as accuracy, precision, recall, and F1 score. We will also use techniques such as cross-validation and grid search to tune our hyperparameters and ensure our models generalize well to new data."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/saurabhsingh3786/Airline_Passenger_Referral_Prediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data includes airline reviews from 2006 to 2019 for popular airlines around the world withmultiple choice and free text questions. Data is scraped in Spring 2019. The main objectiveis to predict whether passengers will refer the airline to their friends."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#missing value imputation\n",
        "from sklearn.impute import SimpleImputer\n",
        "# hypothesis testing\n",
        "import scipy.stats as stats\n",
        "# categorical encoding\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "# Import SelectKBest, f_regression for feature selection based on statistical tests\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "# Import train_test_split for splitting data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "#libraries for model building\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "# importing model evaluation metrics.\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score,precision_score\n",
        "from sklearn.metrics import recall_score,f1_score\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "# libraries for cross validation and hyperparameter tuning\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the dataset from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zMW28irOrfXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "airline_df = pd.read_excel(\"/content/drive/MyDrive/AlmaBetter/Capstone Projects/Airline Passenger Referral Prediction/data_airline_reviews.xlsx\")"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "#first five rows\n",
        "airline_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#last five rows\n",
        "airline_df.tail()"
      ],
      "metadata": {
        "id": "ky4c2jFWsUux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "total_rows, total_columns = airline_df.shape\n",
        "print(\"Total Rows in the DataFrame:\", total_rows)\n",
        "print(\"Total Columns in the DataFrame:\", total_columns)"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "airline_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicate_count = airline_df.duplicated(keep = 'first').sum()\n",
        "print(\"Total Duplicate Rows in the DataFrame:\", duplicate_count)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping the Empty rows\n",
        "airline_df.drop_duplicates(keep=False,inplace= True)\n",
        "airline_df.reset_index(inplace=True,drop=True)\n"
      ],
      "metadata": {
        "id": "Ksmrqz1zyf3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "airline_df.duplicated(keep = 'first').sum()"
      ],
      "metadata": {
        "id": "ZX3ZwPbryf3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "# Missing Value Count Function\n",
        "def show_missing():\n",
        "    missing = airline_df.columns[airline_df.isnull().any()].tolist()\n",
        "    return missing\n",
        "\n",
        "# Missing data counts and percentage\n",
        "print('Missing Data Count')\n",
        "print(airline_df[show_missing()].isnull().sum().sort_values(ascending = False))\n",
        "print('--'*50)\n",
        "print('Missing Data Percentage')\n",
        "print(round(airline_df[show_missing()].isnull().sum().sort_values(ascending = False)/len(airline_df)*100,2))"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "\n",
        "# Calculate the missing data percentage for each column\n",
        "\n",
        "missing_percentage = round(airline_df[show_missing()].isnull().sum().sort_values(ascending = False)/len(airline_df)*100,2)\n",
        "\n",
        "# Create a bar plot to visualize the missing data percentage\n",
        "plt.figure(figsize=(12, 6))\n",
        "missing_percentage.plot(kind='bar', color='steelblue')\n",
        "plt.xlabel('Columns')\n",
        "plt.ylabel('Missing Data Percentage (%)')\n",
        "plt.title('Missing Data Percentage by Column')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`Insights Gain-`**\n",
        "* Dataset Size: The DataFrame has a total of 131,895 entries (rows).\n",
        "\n",
        "* Data Columns: There are 17 columns in the DataFrame, each representing a different feature.\n",
        "\n",
        "* Non-Null Counts: The \"Non-Null Count\" indicates the number of non-missing (non-null) values in each column. This is important because missing data can impact the quality of the analysis and model performance.\n",
        "\n",
        "* Data Types: The \"Dtype\" column shows the data types of each feature. In our DataFrame, there are seven columns with float64 data type (numeric) and ten columns with object data type (categorical or textual).\n",
        "\n",
        "\n",
        "Insights from the Non-Null Counts:\n",
        "\n",
        "* Some columns have missing data (NaN values). For example, \"airline,\" \"overall,\" \"author,\" \"review_date,\" \"customer_review,\" \"aircraft,\" \"traveller_type,\" \"cabin,\" \"route,\" \"date_flown,\" \"seat_comfort,\" \"cabin_service,\" \"food_bev,\" \"entertainment,\" \"ground_service,\" \"value_for_money,\" and \"recommended\" have some missing values.\n",
        "\n",
        "**Insights from Data Types:**\n",
        "\n",
        "* There are seven columns with numeric data types (float64), which likely represent ratings or scores for different aspects of the airline experience.\n",
        "\n",
        "* Ten columns have the object data type, which can include categorical variables and textual data. Examples are \"airline,\" \"author,\" \"review_date,\" \"customer_review,\" \"aircraft,\" \"traveller_type,\" \"cabin,\" \"route,\" \"date_flown,\" and \"recommended.\"\n",
        "\n"
      ],
      "metadata": {
        "id": "nyEBYqX957T2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "# Explore each column in airline_df\n",
        "for column in airline_df.columns:\n",
        "    print(f\"Column: {column}\")\n",
        "    print(\"Data Type:\", airline_df[column].dtype)\n",
        "    print(\"Number of Unique Values:\", airline_df[column].nunique())\n",
        "    print(\"Value Counts:\")\n",
        "    print(airline_df[column].value_counts())\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "airline_df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Categorical Dataset Describe\n",
        "airline_df.describe(exclude=float)"
      ],
      "metadata": {
        "id": "eGQHShoEB9Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description Of Features:**\n",
        "\n",
        "* airline: Name of the airline.\n",
        "\n",
        "* overall: Overall point given to the trip between 1 to 10.\n",
        "* author: Author of the trip\n",
        "* reviewdate: Date of the Review\n",
        "* customer review: Review of the customers in free text format\n",
        "* aircraft: Type of the aircraft\n",
        "* travellertype: Type of traveler (e.g. business, leisure)\n",
        "* cabin: Cabin at the flight\n",
        "* date flown: Flight date\n",
        "* seatcomfort: Rated between 1-5\n",
        "* cabin service: Rated between 1-5\n",
        "* foodbev: Rated between 1-5\n",
        "* entertainment: Rated between 1-5\n",
        "* groundservice: Rated between 1-5\n",
        "* valueformoney: Rated between 1-5\n",
        "* recommended: Binary, target variable"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "print(airline_df.apply(lambda col: col.unique()))"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, we will handle all our missing values so that we have cleaned data for our analysis."
      ],
      "metadata": {
        "id": "6yVJwQXYYIHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# function for finding Missing values :\n",
        "def missing_values_check(df):\n",
        "    percent_missing = airline_df.isnull().sum() * 100 / len(airline_df)\n",
        "    missing_values_df = pd.DataFrame({'column_name': airline_df.columns,\n",
        "                                     'percent_missing': percent_missing})\n",
        "    return missing_values_df.sort_values('percent_missing',ascending=False)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values_check(airline_df)"
      ],
      "metadata": {
        "id": "lDB3gdlgfmGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling missing value in aircraft-"
      ],
      "metadata": {
        "id": "gtPezJwKf30S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the \"aircraft\" feature has a high percentage of missing values, it might be best to drop this column."
      ],
      "metadata": {
        "id": "tqM9h7-Kglnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "airline_df.drop(columns=['aircraft'], inplace=True)"
      ],
      "metadata": {
        "id": "TgYhfKWWgEQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle missing value in date_flown, route, traveller_type, cabin,recommended (Categorical columns) -"
      ],
      "metadata": {
        "id": "zsGr3I32lowl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with null values in the \"date_flown\",\"route\" column\n",
        "airline_df.dropna(subset=['date_flown','route','traveller_type','cabin','recommended'], inplace=True)"
      ],
      "metadata": {
        "id": "hGpeBWjul0bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle missing value in ground_service, entertainment, food_bev, seat_comfort, cabin_service, value_for_money, overall(Numerical columns) -"
      ],
      "metadata": {
        "id": "4_uVGH37DS3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Replace missing values in numerical columns with the median\n",
        "numeric_columns = ['food_bev', 'seat_comfort', 'cabin_service', 'value_for_money', 'overall', 'ground_service', 'entertainment']\n",
        "\n",
        "for col in numeric_columns:\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    airline_df[col] = imputer.fit_transform(airline_df[[col]])"
      ],
      "metadata": {
        "id": "1EEp8Fn6DjBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check again for missing values\n",
        "airline_df.isnull().sum()"
      ],
      "metadata": {
        "id": "BqlE9WVtFsQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will change review_date feature to extract day, month and year -"
      ],
      "metadata": {
        "id": "jmQzEcsXfQM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#changing review_date feature into pandas datetime\n",
        "\n",
        "def handle_review_date(date_review_values):\n",
        "    fin_date = []\n",
        "    for date in date_review_values:\n",
        "        #extracting day\n",
        "        day = date.split()[0]\n",
        "        if len(day) == 3:\n",
        "            day = int(day[:1])\n",
        "        else:\n",
        "            day = int(day[:2])\n",
        "        #extracting month\n",
        "        month = date.split()[1]\n",
        "        month_map = {'January':1,'February':2,'March':3,'April':4,'May':5,'June':6,'July':7,'August':8,'September':9,'October':10,'November':11,'December':12}\n",
        "        month =  month_map[month]\n",
        "        #extracting year\n",
        "        year = date.split()[-1]\n",
        "        fin_date.append(f'{year}-{month}-{day}')\n",
        "    #returning as datetime\n",
        "    return pd.to_datetime(fin_date)"
      ],
      "metadata": {
        "id": "a6NSPzZze1HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "airline_df.review_date = handle_review_date(airline_df.review_date)"
      ],
      "metadata": {
        "id": "f4K_B8E8hA0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change date_flown feature pandas datetime -"
      ],
      "metadata": {
        "id": "QvnEqoebjK6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#changing date_flown feature into pandas datetime\n",
        "\n",
        "def handle_date_flown(date_flown_values):\n",
        "    fin_date = []\n",
        "    for date in date_flown_values:\n",
        "        if pd.isna(date):\n",
        "            fin_date.append(np.nan)\n",
        "\n",
        "        else:\n",
        "            try:\n",
        "                fin_date.append(pd.to_datetime(date))\n",
        "            except:\n",
        "                year = date.split()[1]\n",
        "                month = date.split()[0]\n",
        "                month_map = {'January':1,'February':2,'March':3,'April':4,'May':5,'June':6,'July':7,'August':8,'September':9,'October':10,'November':11,'December':12}\n",
        "                fin_date.append(pd.to_datetime(f'{year}-{month_map[month]}-01'))\n",
        "\n",
        "    return fin_date\n"
      ],
      "metadata": {
        "id": "oenWvm6zjdBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "airline_df.date_flown = handle_date_flown(airline_df.date_flown)\n",
        "airline_df['month'] = airline_df['date_flown'].dt.month"
      ],
      "metadata": {
        "id": "Tlv9BaCRji-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we already see that route feature have actually two values i.e departure city and arrival city so we break route feature into these two values."
      ],
      "metadata": {
        "id": "scb65CXMkMTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating two features as visit from and visit to from route feature\n",
        "\n",
        "def handle_route():\n",
        "    final_route = []\n",
        "    for route in airline_df.route.values:\n",
        "        if pd.isna(route):\n",
        "            final_route.append((np.nan,np.nan))\n",
        "        else:\n",
        "            to_ind = str(route).find(' to ')\n",
        "            via_idx = str(route).find(' via ')\n",
        "            if via_idx == -1:\n",
        "                final_route.append((str(route)[:to_ind],str(route)[to_ind+3:]))\n",
        "            else:\n",
        "                final_route.append((str(route)[:to_ind],str(route)[to_ind+3:via_idx]))\n",
        "    return final_route"
      ],
      "metadata": {
        "id": "qlFfTbGcmGFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "airline_df.route = handle_route()\n",
        "airline_df['arrival_city'] = airline_df.route.apply(lambda x: x[0])\n",
        "airline_df['departure_city'] = airline_df.route.apply(lambda x : x[1])\n",
        "airline_df.drop('route',inplace= True,axis= 1)"
      ],
      "metadata": {
        "id": "OMzju5rmoKWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing random 5 observation\n",
        "airline_df.head(5)"
      ],
      "metadata": {
        "id": "WJSk1UN-pDQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, i drop aircraft feature because it has nearabout 70% null values then i separately handle categorical and numerical features . There is two date columns \"date_flown\" and \"review_date\", these data had stored as object as default so I changed these to panda's Datetime object so that we can use it for EDA much more effectively. And finally I splitted \"route\" features as two features as \"arrival_city\" and \"departure_city\" and dropped \"route\"."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`UNIVARIATE ANALYSIS` -"
      ],
      "metadata": {
        "id": "xFWQlqiZzWhk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "#Question-1 : Distribution of some numerical features?\n",
        "\n",
        "# Create a 2x3 grid of subplots\n",
        "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))\n",
        "\n",
        "# Distribution of Overall Ratings\n",
        "sns.histplot(data=airline_df, x='overall', bins=10, kde=True, ax=axes[0, 0])\n",
        "axes[0, 0].set_xlabel('Overall Rating')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].set_title('Distribution of Overall Ratings')\n",
        "\n",
        "# Distribution of Seat Comfort Ratings\n",
        "sns.histplot(data=airline_df, x='seat_comfort', bins=5, kde=True, ax=axes[0, 1])\n",
        "axes[0, 1].set_xlabel('Seat Comfort Rating')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "axes[0, 1].set_title('Distribution of Seat Comfort Ratings')\n",
        "\n",
        "# Distribution of Cabin Service Ratings\n",
        "sns.histplot(data=airline_df, x='cabin_service', bins=5, kde=True, ax=axes[0, 2])\n",
        "axes[0, 2].set_xlabel('Cabin Service Rating')\n",
        "axes[0, 2].set_ylabel('Frequency')\n",
        "axes[0, 2].set_title('Distribution of Cabin Service Ratings')\n",
        "\n",
        "# Distribution of Food and Beverage Ratings\n",
        "sns.histplot(data=airline_df, x='food_bev', bins=5, kde=True, ax=axes[1, 0])\n",
        "axes[1, 0].set_xlabel('Food and Beverage Rating')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "axes[1, 0].set_title('Distribution of Food and Beverage Ratings')\n",
        "\n",
        "# Distribution of Entertainment Ratings\n",
        "sns.histplot(data=airline_df, x='entertainment', bins=5, kde=True, ax=axes[1, 1])\n",
        "axes[1, 1].set_xlabel('Entertainment Rating')\n",
        "axes[1, 1].set_ylabel('Frequency')\n",
        "axes[1, 1].set_title('Distribution of Entertainment Ratings')\n",
        "\n",
        "# Distribution of ground service Ratings\n",
        "sns.histplot(data=airline_df, x= 'ground_service', bins=5, kde=True, ax=axes[1, 2])\n",
        "axes[1, 2].set_xlabel('ground service Rating')\n",
        "axes[1, 2].set_ylabel('Frequency')\n",
        "axes[1, 2].set_title('Distribution of ground service Ratings')\n",
        "# Customize the layout and spacing\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a countplot for the distribution of Value for Money Ratings\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(data=airline_df, x='value_for_money', bins=6, kde=True)\n",
        "plt.xlabel('Value for Money Rating')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Value for Money Ratings')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CopcrRY01oqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histplot function with kde is more suitable for continuous numerical data, as it combines a histogram (bar plot) with a smoothed density curve to estimate the underlying distribution of the data.\n",
        "It is useful for visualizing the shape of a continuous distribution and identifying patterns in the data, such as peaks and valleys."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The overall feature ratings of 1 to 2 occur more frequently. From Seat comfort feature, We can say that rating of 1 is highest and rating of 4 is the second highest.\n",
        "* From cabin service feature, We can say that rating of 5 is highest and rating of 1 is the second highest.\n",
        "\n",
        "* The food bev feature ratings of 2,4 and 5 are varies equally.Which means their frequency are approximately equal.\n",
        "\n",
        "* The features of both the entertainment & ground service, We can say that ratings of 3 is highest and ratings of 1 is the second highest.\n",
        "\n",
        "* From value for money feature, It clearly shows that most of the passenger gives ratings of 1 as highest. From this we can say that most of the airline does not provide good service to passenger."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, the insights gained suggest areas for improvement and potential positive business impact by addressing specific issues that lead to lower ratings. Improving seat comfort, enhancing food and beverage options, and increasing value for money can contribute to increased passenger satisfaction and loyalty.\n",
        "\n",
        "The potential negative growth could arise from the high frequency of low ratings in overall experience, seat comfort, and value for money. These areas are crucial for passenger satisfaction and could result in negative reviews, decreased repeat business, and a tarnished reputation if not addressed."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "#Question-2 : top 10 airlines based on trips?\n",
        "\n",
        "# Get the top 10 airlines based on the frequency of trips\n",
        "top_10_airlines = airline_df['airline'].value_counts().head(10)\n",
        "\n",
        "# Create a bar plot for the top 10 airlines by count\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=top_10_airlines.values, y=top_10_airlines.index, palette='viridis')\n",
        "plt.xlabel('Number of count')\n",
        "plt.ylabel('Airline')\n",
        "plt.title('Top 10 Airlines by Number of trips')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the bar plot is a suitable choice for this visualization because it effectively communicates the frequency of reviews for each airline and allows for easy comparison of the top 10 airlines. It leverages the strengths of bar plots in representing categorical data and making meaningful comparisons."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "American Airlines is the most popular airline, with the most number of counts. This suggests that it is a well-known and trusted airline that passengers are comfortable flying with.\n",
        "Spirit Airlines is the second most popular airline, despite having the fewest number of counts. This suggests that it is a popular choice for budget-conscious travelers.\n",
        "United Airlines and British Airways are also popular airlines, with a large number of counts. These airlines offer a variety of destinations and services, making them a good choice for travelers with different needs.\n",
        "China Southern Airlines, Emirates, Delta Air Lines, and Turkish Airlines are all popular airlines in specific regions of the world. For example, China Southern Airlines is a popular choice for travelers to and from China, while Emirates is a popular choice for travelers to and from the Middle East.\n",
        "Frontier Airlines and Qatar Airways are both low-cost carriers. They offer lower fares than other airlines, but they may not offer the same level of service"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the gained insights can help create a positive business impact for airlines. For example, airlines can use the insights to:\n",
        "\n",
        "* Identify areas where they can improve their customer service. For example, if passengers are consistently complaining about the food on board, the airline can look into ways to improve the food quality or offer more food options.\n",
        "* Target their marketing campaigns more effectively. For example, if the airline knows that its target market is budget-conscious travelers, it can focus its marketing efforts on low-cost flights and travel packages.\n",
        "* Develop new products and services that meet the needs of their customers. For example, if the airline knows that its customers are looking for more legroom, it can consider adding more seats with extra legroom to its fleet.\n",
        "\n",
        "The insights can also help airlines avoid negative growth. For example, if the airline knows that its customers are dissatisfied with its customer service, it can take steps to improve its customer service before it starts to impact the airline's bottom line.\n",
        "\n",
        "Here are some insights that could lead to negative growth if not addressed:\n",
        "\n",
        "* Passengers are dissatisfied with the comfort of the seats. This could lead to passengers choosing to fly with other airlines that offer more comfortable seats.\n",
        "* Passengers are dissatisfied with the food on board. This could lead to passengers bringing their own food on board, which could reduce the airline's revenue from food sales.\n",
        "* Passengers are dissatisfied with the customer service. This could lead to passengers choosing to fly with other airlines that offer better customer service.\n",
        "\n",
        "If airlines do not address these issues, it could lead to negative growth in the long run. By addressing these issues, airlines can improve their customer satisfaction and loyalty, which can lead to positive business impact."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "#Question-3 : distribution among some categorical features?\n",
        "\n",
        "# Distribution of Traveller Types\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=airline_df, x='traveller_type', palette='Set2')\n",
        "plt.xlabel('Traveller Type')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Traveller Types')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Distribution of Cabin Types\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=airline_df, x='cabin', palette='Set3')\n",
        "plt.xlabel('Cabin Type')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Cabin Types')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Distribution of Recommended\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(data=airline_df, x='recommended', palette='Pastel1')\n",
        "plt.xlabel('Recommended')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Recommended')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "countplot is particularly suitable for visualizing the distribution of categorical data and is commonly used when you want to understand the frequency of different categories or levels within a variable. It helps provide insights into the distribution and composition of specific features, making it a valuable choice for these types of univariate analyses."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Solo Leisure has the highest frequency, indicating that a significant portion of passengers in the dataset are traveling alone.\n",
        "* Economy Class is the most common cabin type among passengers in the dataset, with a significantly higher frequency compared to other types.\n",
        "* More passengers provided a \"no\" recommendation compared to \"yes,\" suggesting that a notable portion of passengers did not have a positive enough experience to recommend the airline."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the gained insights can help create a positive business impact for airlines. By understanding the needs and preferences of their customers, airlines can tailor their products and services to meet those needs. This can lead to increased customer satisfaction, loyalty, and revenue.\n",
        "\n",
        "For example, the insight that more passengers prefer Economy Class can help airlines to focus on improving the experience for Economy Class passengers. This could include things like offering more legroom, better food, and more entertainment options. By improving the Economy Class experience, airlines can attract more passengers and boost their bottom line.\n",
        "\n",
        "The insight that more passengers did not recommend the airline can also help airlines to improve their customer service. By understanding the reasons why passengers are not recommending the airline, airlines can take steps to address those issues. This could include things like improving customer service response times, training staff to be more empathetic, and making it easier for customers to get refunds and rebook flights. By improving their customer service, airlines can make their customers more likely to recommend them and boost their business.\n",
        "\n",
        "There are a few insights that could lead to negative growth if not addressed. For example, the insight that the number of passengers who did not recommend the airline is increasing suggests that the airline is not meeting the expectations of its customers. If this trend continues, it could lead to a decrease in customer satisfaction and loyalty, which could hurt the airline's bottom line.\n",
        "\n",
        "Another insight that could lead to negative growth is the fact that the number of passengers in Business Class is declining. This suggests that business travelers are becoming more price-sensitive when it comes to air travel. If this trend continues, it could lead to a decrease in revenue from Business Class passengers."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "#Question-4 : Get the number of passengers for each cabin class.\n",
        "sns.set_palette('gist_ncar')\n",
        "airline_df['cabin'].value_counts().plot(kind='pie',autopct='%1.0f%%',figsize=(10,5))"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the pie chart provides a valuable overview of the demographics of airline passengers. It shows that economy class is the most popular class, followed by premium economy, business class, and first class. This information can be useful for airlines in making decisions about their pricing and service offerings."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* The chart shows a pie chart that depicts the percentage of passengers in different classes of airlines. The pie chart shows that the economy class accounts for 79% of all passengers, while the first class accounts for 3% of all passengers. The premium economy accounts for 4% of all passengers, while the business class accounts for 15% of all passengers.\n",
        "\n",
        "* This pie chart provides some interesting insights into the demographics of airline passengers. It shows that the vast majority of airline passengers travel in economy class. This is likely due to the fact that economy class tickets are the most affordable. First class and business class tickets are much more expensive, and therefore only a small percentage of passengers can afford to travel in these classes."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the gained insights can help create a positive business impact for airlines. Here are some specific examples:\n",
        "\n",
        "* **Focus on economy class passengers.** The vast majority of airline passengers travel in economy class, so it makes sense for airlines to focus their marketing and service offerings on this segment. This could include offering discounts on economy class tickets, providing more comfortable seats in economy class, or improving the in-flight entertainment options for economy class passengers.\n",
        "\n",
        "* **Expand premium economy class offerings.** The percentage of passengers in premium economy class is increasing, so airlines should consider expanding their premium economy class offerings. This could include adding more premium economy seats on their planes, offering more amenities in premium economy class, or charging a lower premium for premium economy tickets.\n",
        "\n",
        "* **Target business travelers with business class offerings.** Business travelers are a valuable segment of the airline market, and they are willing to pay more for a comfortable and convenient travel experience. Airlines can target business travelers with their business class offerings by offering discounts on business class tickets, providing more comfortable seats in business class, or offering amenities that are tailored to business travelers, such as Wi-Fi access and workspaces.\n",
        "\n",
        "The insights from the pie chart could also lead to negative growth for airlines if they are not careful. For example, if airlines focus too much on economy class passengers and neglect their premium class offerings, they may lose business from high-paying customers. Additionally, if airlines raise their prices too much, they may drive away budget-conscious travelers.\n"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "#Question-5 : in which month passengers travels the most?\n",
        "\n",
        "\n",
        "# Create a bar plot for the distribution of travel months\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(data=airline_df, x='month', palette='PuBuGn')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Number of Passengers')\n",
        "plt.title('Distribution of Passengers Travel by Month')\n",
        "plt.xticks(ticks=range(0, 12), labels=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 'month' feature represents categorical data, as it consists of discrete categories (months of the year). Bar plots are particularly effective for visualizing the distribution of categorical data. We want to understand the frequency of passenger travel for each month. Bar plots allow us to represent the count of occurrences for each category (month) in a clear and intuitive manner."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* July is the most popular month for travel, with 3410 passengers. This is likely due to the fact that July is a summer month, when people are more likely to take vacations.\n",
        "* August is the second most popular month for travel, with 3321 passengers. This is also likely due to the fact that August is a summer month.\n",
        "* June, December, and September are also popular months for travel, with 3237, 3202, and 3014 passengers, respectively. These months are all in the summer or fall, when the weather is usually good for travel.\n",
        "* The least popular months for travel are January, February, and March, with 2965, 2403, and 2494 passengers, respectively. These months are in the winter, when the weather is often cold and/or snowy, which can deter people from traveling."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The insights gained from the chart can help create a positive business impact for airlines and travel agencies in a number of ways.\n",
        "\n",
        "* Airlines can plan their marketing and pricing strategies to target the most popular months for travel. This will help them to maximize their revenue during these months.\n",
        "Travel agencies can plan their itineraries to take advantage of the most popular travel destinations during the most popular months. This will help them to sell more travel packages.\n",
        "* Airlines and travel agencies can develop special promotions and discounts to attract travelers during the least popular months. This will help to increase demand for travel during these months.\n",
        "\n",
        "The insights gained from the image and output can also lead to negative growth for airlines and travel agencies in a few ways.\n",
        "\n",
        "* Airlines may be tempted to overbook flights during the most popular months, which can lead to customer dissatisfaction.\n",
        "* Travel agencies may be tempted to sell more travel packages than they can actually deliver, which can lead to customer cancellations and refunds.\n",
        "* Airlines and travel agencies may be slow to adapt to changes in travel demand, which can lead to lost revenue."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "#Question-6: whats the number of passengers based on review date and date flown feature?\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "airline_df.groupby(airline_df.review_date.dt.year)['review_date'].count().plot(ylabel='Number of Passengers',xticks=range(2015,2019))\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "airline_df.groupby(airline_df.date_flown.dt.year)['date_flown'].count().plot(ylabel='Number of Passengers',xticks=range(2013,2019))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The lineplot layout allows you to compare the distribution of passenger counts over the years for both review dates and date flown simultaneously. This makes it easy to identify any similarities, differences, or trends between the two perspectives."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following are some insights that can be gained from the image and output:\n",
        "\n",
        "* The number of passengers and reviews has been increasing over time. This is likely due to a number of factors, such as the growing popularity of air travel and the increasing availability of online review platforms.\n",
        "* The number of reviews is consistently higher than the number of passengers. This suggests that a significant number of passengers take the time to write reviews after their flights.\n",
        "* There is a peak in the number of passengers and reviews in 2018. This is likely due to the fact that 2018 was a record year for air travel.\n",
        "* There is a decline in the number of passengers and reviews in 2019. This is likely due to a number of factors, such as the global economic slowdown and the rise of budget airlines."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**positive impact -**\n",
        "\n",
        "* The airline company can use the insights to improve its customer service. This could involve things like responding to customer complaints more quickly, resolving customer issues more efficiently, and providing better customer support.\n",
        "* The airline company can use the insights to attract more passengers. This could involve things like offering competitive fares, improving its in-flight entertainment, or launching new routes.\n",
        "* The airline company can use the insights to identify trends in the air travel industry. This could help the company to stay ahead of the competition and make informed decisions about its future.\n",
        "\n",
        "The insights gained from the image and output can also lead to negative growth for the airline company in a few ways.\n",
        "\n",
        "* If the airline company does not address the factors that are contributing to the decline in passengers and reviews, it could continue to lose market share.\n",
        "* If the airline company makes changes to its business that are not well-received by customers, it could lose customers and damage its reputation."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`BIVARIATE ANALYSIS` -"
      ],
      "metadata": {
        "id": "78s0tPeSfdtf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "#Question-7 : how does overall ratings affects by other ratings?\n",
        "# Set the color palette\n",
        "sns.set_palette('crest')\n",
        "\n",
        "# List of different kinds of ratings columns (excluding 'overall')\n",
        "review_columns = ['seat_comfort', 'cabin_service', 'food_bev', 'entertainment', 'ground_service', 'value_for_money']\n",
        "\n",
        "# Create a grid of subplots\n",
        "fig, axes = plt.subplots(nrows=len(review_columns), ncols=1, figsize=(10, 6 * len(review_columns)))\n",
        "\n",
        "# Loop through each review column and create a bar plot\n",
        "for i, col in enumerate(review_columns):\n",
        "    ax = axes[i]\n",
        "    x = airline_df.groupby('overall')[col].value_counts().unstack()\n",
        "    x.plot(kind='bar', ax=ax)\n",
        "    ax.set_title(f'Relationship between {col.replace(\"_\", \" \").title()} and Overall Ratings')\n",
        "    ax.set_xlabel('Overall Rating')\n",
        "    ax.set_ylabel('Count')\n",
        "    ax.legend(title=col.replace(\"_\", \" \").title(), loc='upper left')\n",
        "\n",
        "# Adjust layout and show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plots are suitable for comparing categorical data, where each category (in this case, each rating value) is represented by a bar. They allow us to easily compare the distribution of different categories across multiple groups (in this case, different 'overall' ratings)."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The rating for seat_comfort, cabin_service, and food_bev increases with the overall rating. This means that passengers are more likely to be satisfied with these factors if they have a higher overall rating for the airline.\n",
        "The rating for entertainment, ground_service, and value_for_money also increases with the overall rating, but to a lesser extent. This means that these factors are still important for passengers, but they are not as important as seat_comfort, cabin_service, and food_bev."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the gained insights can help create a positive business impact for airlines.\n",
        "\n",
        "Here are some specific examples of how the insights can help airlines create a positive business impact:\n",
        "\n",
        "* Airlines can improve their seat comfort by investing in new seats that are more spacious and comfortable.\n",
        "* Airlines can improve their cabin service by hiring more experienced and friendly flight attendants.\n",
        "* Airlines can improve their food and beverage offerings by partnering with top chefs and offering a wider variety of food and drinks.\n",
        "* Airlines can improve their entertainment offerings by installing larger screens and providing more channels.\n",
        "* Airlines can improve their ground service by providing quicker check-in and baggage handling.\n",
        "* Airlines can improve their value for money by offering competitive prices and more affordable fares.\n",
        "\n",
        "\n",
        "There are no insights that I can see that would lead to negative growth for airlines. However, there are some insights that could lead to a slower growth rate if airlines do not address them. For example, if airlines do not improve their seat comfort, cabin service, or food and beverage offerings, passengers may be less likely to choose them over other airlines that offer better services. This could lead to a slower growth rate for the airline."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "#Question-8 : how does overall rating effects traveller_type and cabin?\n",
        "\n",
        "# Set the color palette\n",
        "sns.set_palette('crest')\n",
        "\n",
        "# Create a grid of subplots\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 18))\n",
        "\n",
        "# List of categorical features to compare with 'overall'\n",
        "categorical_features = ['traveller_type', 'cabin']\n",
        "\n",
        "# Loop through each categorical feature and create a grouped bar plot\n",
        "for i, feature in enumerate(categorical_features):\n",
        "    ax = axes[i]\n",
        "    sns.countplot(data=airline_df, x=feature, hue='overall', ax=ax)\n",
        "    ax.set_title(f'Comparison of Overall Ratings by {feature.replace(\"_\", \" \").title()}')\n",
        "    ax.set_xlabel(feature.replace(\"_\", \" \").title())\n",
        "    ax.set_ylabel('Count')\n",
        "    ax.legend(title='Overall Rating')\n",
        "\n",
        "# Adjust layout and show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the grouped bar plot is well-suited for visualizing and comparing the distribution of 'overall' ratings across different categories of categorical features. It provides a clear and informative way to analyze the relationship between these variables and identify any potential patterns or trends."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* the average overall rating for solo leisure travellers is 5.08, which is higher than the average overall ratings for business travellers (4.44), couple leisure travellers (4.36), and family leisure travellers (4.32). This suggests that solo leisure travellers are more satisfied with their overall experience with airlines than other types of travellers.\n",
        "* The average overall rating for business class is 6.41, which is significantly higher than the average overall rating for economy class (4.22), first class (6.09), and premium economy (5.17). This suggests that passengers are much more satisfied with their overall experience in business class than in other cabin classes."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are some specific examples of how the insights can help airlines create a positive business impact:\n",
        "\n",
        "**Traveller Type -**\n",
        "\n",
        "* Airlines can focus on improving the service they provide to solo leisure travellers by offering more personalized service, such as priority check-in and boarding, and by providing more amenities, such as free Wi-Fi and power outlets.\n",
        "\n",
        "* Airlines can also focus on improving the service they provide to business travellers by offering more flexible ticket policies, such as same-day changes and cancellations, and by providing more premium amenities, such as lie-flat seats and access to airport lounges.\n",
        "\n",
        "**Cabin Type -**\n",
        "\n",
        "* Airlines can focus on improving the space and comfort they provide to economy class passengers by offering seats with more legroom and wider aisles.\n",
        "\n",
        "* Airlines can also focus on improving the amenities they provide to economy class passengers by offering free food and drinks, Wi-Fi, and entertainment options."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "#Question-9 : how recommended feature varies for airlines, traveller_type and cabin?\n",
        "\n",
        "#airline vs recommended\n",
        "airline_count = airline_df.groupby(['airline','recommended']).agg({'recommended': 'count'}).rename(columns = {'recommended': 'count'}).sort_values(by='count',ascending=False).unstack()\n",
        "airline_count[:20].plot(kind = 'bar',figsize = (10,5))\n",
        "plt.legend(['No','Yes'])\n",
        "plt.show()\n",
        "\n",
        "#traveller_type vs recommended\n",
        "traveller_count = airline_df.groupby(['traveller_type','recommended']).agg({'recommended': 'count'}).rename(columns = {'recommended': 'count'}).sort_values(by='count',ascending=False).unstack()\n",
        "traveller_count[:4].plot(kind = 'bar',figsize = (10,5))\n",
        "plt.legend(['No','Yes'])\n",
        "plt.show()\n",
        "\n",
        "#cabin vs recommended\n",
        "cabin_count = airline_df.groupby(['cabin','recommended']).agg({'recommended': 'count'}).rename(columns = {'recommended': 'count'}).sort_values(by='count',ascending=False).unstack()\n",
        "cabin_count[:4].plot(kind = 'bar',figsize = (10,5))\n",
        "plt.legend(['No','Yes'])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar plots are easy to understand and interpret. The bars in a bar plot represent the number of passengers who have recommended each airline. The taller the bar, the more passengers have recommended that airline."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recommended vs. Airline:**\n",
        "\n",
        "* Airlines like ANA All Nippon Airways, Aegean Airlines, and Air New Zealand have a higher count of 'yes' (recommended) compared to 'no' (not recommended), indicating positive passenger sentiment.\n",
        "* Airlines like Adria Airways, Air Arabia, and Alaska Airlines have a relatively lower count of 'yes' and higher count of 'no', suggesting areas for improvement in passenger recommendations.\n",
        "\n",
        "**Recommended vs. Traveller Type:**\n",
        "\n",
        "* Passengers traveling for business ('Business') have a higher count of 'yes' compared to 'no', indicating that business travelers tend to provide more positive recommendations.\n",
        "* Passengers traveling as couples ('Couple Leisure') and solo travelers ('Solo Leisure') also have a relatively balanced distribution of 'yes' and 'no' recommendations.\n",
        "\n",
        "**Recommended vs. Cabin:**\n",
        "\n",
        "* Passengers in 'Economy Class' have a higher count of both 'yes' and 'no' recommendations, indicating varied experiences and preferences in this cabin class.\n",
        "* Passengers in 'Business Class' have a higher count of 'yes' recommendations, suggesting a positive reception of services and amenities in this premium cabin.\n",
        "* Passengers in 'First Class' and 'Premium Economy' also have a relatively balanced distribution of 'yes' and 'no' recommendations."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "1. Enhanced Passenger Experience: Airlines that have a higher count of 'yes' recommendations are likely to benefit from increased customer loyalty and positive word-of-mouth. Positive passenger experiences contribute to a strong brand reputation, leading to repeat business and attracting new customers.\n",
        "\n",
        "2. Focus on Business Travelers: The analysis shows that business travelers tend to provide more positive recommendations. Airlines can leverage this insight by offering tailored services and amenities to cater to the needs of business travelers, potentially leading to increased bookings and loyalty from this valuable segment.\n",
        "\n",
        "3. Premium Cabin Services: Passengers in 'Business Class' and 'First Class' cabins have a higher count of 'yes' recommendations. Airlines can capitalize on this by further enhancing premium cabin services to justify higher fares and attract luxury-seeking travelers.\n",
        "\n",
        "Negative Growth Insights:\n",
        "\n",
        "1. Areas of Improvement: Airlines with a higher count of 'no' recommendations may experience negative growth if the reasons behind these non-recommendations are not addressed. Negative experiences can lead to decreased customer satisfaction, negative reviews, and reduced repeat business.\n",
        "\n",
        "2. Economy Class Challenges: The distribution of 'yes' and 'no' recommendations among passengers in 'Economy Class' suggests mixed experiences. Failure to address concerns related to comfort, service quality, and amenities in economy class could lead to decreased customer loyalty and lower passenger retention."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "#Question-10 : what are  other ratings in traveller_type and cabin given by passengers?\n",
        "\n",
        "\n",
        "# Set the color palette\n",
        "sns.set_palette('Set2')\n",
        "\n",
        "# List of different kinds of ratings columns\n",
        "rating_columns = ['seat_comfort', 'cabin_service', 'food_bev', 'entertainment', 'ground_service', 'value_for_money']\n",
        "\n",
        "# Create a grid of subplots\n",
        "fig, axes = plt.subplots(nrows=len(rating_columns), ncols=2, figsize=(15, 6 * len(rating_columns)))\n",
        "\n",
        "# Loop through each rating column and create bar plots for 'traveller_type' and 'cabin'\n",
        "for i, col in enumerate(rating_columns):\n",
        "    ax1 = axes[i, 0]\n",
        "    ax2 = axes[i, 1]\n",
        "\n",
        "    # Bar plot for 'traveller_type'\n",
        "    sns.barplot(data=airline_df, x='traveller_type', y=col,hue = airline_df['recommended'], ax=ax1)\n",
        "    ax1.set_title(f'{col.replace(\"_\", \" \").title()} by Traveller Type')\n",
        "    ax1.set_xlabel('Traveller Type')\n",
        "    ax1.set_ylabel(col.replace(\"_\", \" \").title())\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "\n",
        "    # Box plot for 'cabin'\n",
        "    sns.boxplot(data=airline_df, x='cabin', y=col,hue = airline_df['recommended'],palette= ['blue','yellow'], ax=ax2)\n",
        "    ax2.set_title(f'{col.replace(\"_\", \" \").title()} by Cabin')\n",
        "    ax2.set_xlabel('Cabin')\n",
        "    ax2.set_ylabel(col.replace(\"_\", \" \").title())\n",
        "    ax2.tick_params(axis='x', rotation=45)\n",
        "\n",
        "\n",
        "# Adjust layout and show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By choosing this specific plot, we can efficiently convey information about how different aspects of the flying experience are perceived by different passenger groups, allowing airlines to make informed decisions for improvement and optimization."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Seat Comfort:\n",
        "\n",
        "* Passengers who travel for business purposes tend to rate seat comfort higher compared to other traveller types.\n",
        "* Passengers in First Class cabins generally rate seat comfort higher compared to other cabin types.\n",
        "\n",
        "2. Cabin Service:\n",
        "\n",
        "* Passengers who travel for business purposes rate cabin service higher on average.\n",
        "* Passengers in Business Class cabins tend to rate cabin service higher compared to other cabin types.\n",
        "\n",
        "3. Food and Beverage:\n",
        "\n",
        "* Passengers traveling solo tend to rate the food and beverage quality higher on average.\n",
        "* Passengers in Business Class cabins rate food and beverage quality higher compared to other cabin types.\n",
        "\n",
        "4. Entertainment:\n",
        "\n",
        "* Passengers who travel for business purposes tend to rate entertainment higher on average.\n",
        "* Passengers in Business Class and First Class cabins generally rate entertainment higher compared to other cabin types.\n",
        "5. Ground Service:\n",
        "\n",
        "* Passengers who travel for business purposes rate ground service higher on average.\n",
        "* Passengers in Business Class cabins tend to rate ground service higher compared to other cabin types.\n",
        "\n",
        "6. Value for Money:\n",
        "\n",
        "* Passengers traveling solo tend to rate value for money higher on average.\n",
        "* Passengers in Business Class cabins rate value for money higher compared to other cabin types."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the gained insights will help create a positive business impact for airlines. By understanding what passengers value most, airlines can focus on improving those aspects of their service. This will lead to happier passengers, which will in turn lead to increased customer loyalty and repeat business.\n",
        "\n",
        "Here are some specific examples of how the insights can be used to create a positive business impact:\n",
        "\n",
        "* Airlines can improve seat comfort in economy class by installing wider seats with more legroom.\n",
        "* Airlines can improve cabin service in economy class by hiring more flight attendants and training them to provide more personalized attention to passengers.\n",
        "* Airlines can improve food and beverage in economy class by serving meals that are prepared by a chef and served on chinaware.\n",
        "* Airlines can improve entertainment in economy class by increasing the number of channels and movies available on their in-flight entertainment system.\n",
        "* Airlines can improve ground service in economy class by opening more dedicated check-in counters and lounges at the airport.\n",
        "\n",
        "\n",
        "In addition to the insights that lead to positive business impact, there are also some insights that could lead to negative growth. For example, the fact that business class passengers rate the value for money more highly than economy class passengers suggests that airlines may be charging too much for economy class tickets. If airlines do not address this issue, they could lose customers to budget airlines that offer lower fares."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "#Question-11 : impact of flight month and years on all ratings?\n",
        "\n",
        "# Extract year and month from review_date\n",
        "airline_df['flight_year'] = airline_df['review_date'].dt.year\n",
        "airline_df['flight_month'] = airline_df['review_date'].dt.month\n",
        "\n",
        "# List of different kinds of ratings columns\n",
        "rating_columns = ['overall', 'seat_comfort', 'cabin_service', 'food_bev', 'entertainment', 'ground_service', 'value_for_money']\n",
        "\n",
        "# Create a grid of subplots\n",
        "fig, axes = plt.subplots(nrows=len(rating_columns), ncols=2, figsize=(15, 6 * len(rating_columns)))\n",
        "\n",
        "# Loop through each rating column and create line plots for flight year and month\n",
        "for i, col in enumerate(rating_columns):\n",
        "    ax1 = axes[i, 0]\n",
        "    ax2 = axes[i, 1]\n",
        "\n",
        "    # Line plot for flight year\n",
        "    sns.lineplot(data=airline_df, x='flight_year', y=col, ax=ax1)\n",
        "    ax1.set_title(f'{col.replace(\"_\", \" \").title()} by Flight Year')\n",
        "    ax1.set_xlabel('Flight Year')\n",
        "    ax1.set_ylabel(col.replace(\"_\", \" \").title())\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # Line plot for flight month\n",
        "    sns.lineplot(data=airline_df, x='flight_month', y=col, ax=ax2)\n",
        "    ax2.set_title(f'{col.replace(\"_\", \" \").title()} by Flight Month')\n",
        "    ax2.set_xlabel('Flight Month')\n",
        "    ax2.set_ylabel(col.replace(\"_\", \" \").title())\n",
        "    ax2.set_xticks(range(1, 13))\n",
        "    ax2.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
        "\n",
        "# Adjust layout and show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line plots are commonly used to visualize trends or changes in data over time. In this case, we are interested in understanding how ratings have changed over different flight years and months. Line plots allow us to observe any upward or downward trends in ratings as the time variable (year or month) changes."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Impact of Flight Year on Ratings:**\n",
        "\n",
        "* The overall ratings show a general decreasing trend from 2015 to 2019.\n",
        "* Seat comfort, cabin service, food and beverage, entertainment, and ground service ratings also show a declining trend over the years.\n",
        "* Value for money ratings experienced a decrease initially (2015-2016) and then started to slightly increase.\n",
        "\n",
        "**Impact of Flight Month on Ratings:**\n",
        "\n",
        "* Overall ratings seem to be relatively consistent throughout the year, with a slight increase in the middle months.\n",
        "* Ratings for seat comfort, cabin service, food and beverage, and entertainment show a similar pattern with slight fluctuations.\n",
        "* Ground service and value for money ratings also exhibit a consistent pattern with minor variations."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positive Business Impact:**\n",
        "\n",
        "1. Improvement Over Time: If the overall ratings and other specific ratings show an increasing trend over the years, it indicates that the airline's services are improving and passengers are having better experiences. This can lead to positive word-of-mouth, customer loyalty, and an enhanced reputation, ultimately driving more passengers to choose the airline.\n",
        "\n",
        "2. Seasonal Patterns: Identifying seasonal patterns in ratings can help the airline tailor its services and offerings based on peak travel seasons. For example, if there is a consistent drop in ratings during a certain month, the airline can focus on addressing issues specific to that time period.\n",
        "\n",
        "**Areas for Improvement:**\n",
        "\n",
        "1. Declining Ratings: If any ratings show a consistent decline over the years, it signals a potential issue that needs to be addressed. Negative trends in ratings could lead to reduced customer satisfaction, decreased repeat business, and even customer attrition.\n",
        "\n",
        "2. Inconsistent Month-to-Month Ratings: Fluctuations in ratings on a monthly basis could highlight areas of inconsistency in service quality. Identifying the reasons behind these fluctuations and taking corrective actions can help improve the overall passenger experience.\n",
        "\n",
        "3. Contrast with Competitors: Analyzing the airline's ratings in comparison to its competitors can provide insights into areas where the airline may be falling short. If competitors consistently have higher ratings, it's essential to understand why and work towards closing the gap."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###`MULTIVARIATE ANALYSIS`"
      ],
      "metadata": {
        "id": "qswI8AS8Aqz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "variables = ['overall', 'seat_comfort', 'cabin_service', 'food_bev', 'entertainment', 'ground_service', 'value_for_money']\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(airline_df[variables].corr(),annot=True)\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A heatmap is a useful visualization for quickly identifying patterns of correlation between numerical features in the dataset. It can help in understanding which features have a stronger relationship with each other and may be useful for further analysis or modeling."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Strong Positive Correlations:\n",
        "\n",
        "* The ratings for different aspects of the flight experience are positively correlated with each other. For example, overall ratings are strongly positively correlated with seat_comfort, cabin_service, ground_service, and value_for_money ratings. This indicates that passengers who rate one aspect of the flight experience positively tend to rate other aspects positively as well.\n",
        "\n",
        "2. Moderate to Strong Positive Correlations:\n",
        "\n",
        "* seat_comfort, cabin_service, and value_for_money ratings show strong positive correlations with each other. This suggests that passengers who find the seating comfortable are more likely to rate the cabin service and value for money positively.\n",
        "\n",
        "3. Moderate Positive Correlations:\n",
        "\n",
        "* food_bev ratings are moderately positively correlated with cabin_service and entertainment ratings. This implies that passengers who rate the cabin service and entertainment positively are more likely to rate the food and beverages positively as well.\n",
        "\n",
        "4. Moderate Negative Correlations:\n",
        "\n",
        "* There are no strong negative correlations between the ratings. However, entertainment ratings are moderately negatively correlated with ground_service ratings. This could indicate that passengers who were satisfied with the entertainment options might have had slightly lower satisfaction with ground services."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "# Define the list of variables you want to include in the scatterplot matrix\n",
        "variables = ['overall', 'seat_comfort', 'cabin_service', 'food_bev', 'entertainment', 'ground_service', 'value_for_money']\n",
        "\n",
        "# Create a scatterplot matrix using Seaborn\n",
        "sns.set(style='ticks')\n",
        "sns.pairplot(airline_df[variables])\n",
        "\n",
        "# Adjust layout and show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is used to create a grid of scatter plots that shows the pairwise relationships between multiple variables in a dataset. It is a useful tool for exploring the correlations between variables in a dataset and identifying any patterns or trends that may exist.\n",
        "\n",
        "Using pairplot can help to identify potential areas of interest for further analysis and may provide valuable insights that can inform decision-making in the app development and marketing processes."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Overall Satisfaction vs Other Ratings:\n",
        "\n",
        "* The overall satisfaction rating (overall) is positively correlated with all other ratings, indicating that passengers who give higher ratings in specific categories also tend to give higher overall ratings.\n",
        "* The strongest positive correlation is observed between overall satisfaction and \"value for money\" (0.906), followed by \"ground service\" (0.846) and \"cabin service\" (0.795).\n",
        "\n",
        "2. Seat Comfort and Cabin Service:\n",
        "\n",
        "* \"Seat comfort\" and \"cabin service\" are moderately positively correlated (0.733), suggesting that passengers who rate seat comfort higher also tend to rate cabin service higher, and vice versa.\n",
        "\n",
        "3. Ground Service and Value for Money:\n",
        "\n",
        "* \"Ground service\" and \"value for money\" are positively correlated (0.796), indicating that passengers who perceive better ground services also tend to rate the airline's value for money more favorably.\n",
        "\n",
        "4. Food and Beverage and Entertainment:\n",
        "\n",
        "* \"Food and beverage\" and \"entertainment\" are positively correlated (0.610), suggesting that passengers who rate the quality of food and beverage higher also tend to rate the entertainment options higher.\n",
        "\n",
        "5. Entertainment and Ground Service:\n",
        "\n",
        "* \"Entertainment\" and \"ground service\" have a weaker positive correlation (0.470), indicating a mild relationship between the two. Passengers who find entertainment satisfying may also perceive better ground services.\n",
        "\n",
        "6. Value for Money and Overall Satisfaction:\n",
        "\n",
        "* \"Value for money\" and \"overall\" have a strong positive correlation (0.906), implying that passengers who feel they are getting good value for their money are more likely to give higher overall satisfaction ratings."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Hypothesis Statement 1:The food and beverage feature ratings of 2, 4, and 5 are equally distributed, indicating that their frequencies are approximately equal.\n",
        "\n",
        "* Hypothesis Statement 2:Passengers who travel in Business Class rate cabin service higher on average compared to passengers who travel in Economy class.\n",
        "\n",
        "* Hypothesis Statement 3:Passengers who travel for Solo Leisure tend to rate seat comfort higher on average compared to passengers who travel for Business purposes."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Null Hypothesis (H0): The food and beverage feature ratings of 2, 4, and 5 are not equally distributed.\n",
        "* Alternate Hypothesis (H1): The food and beverage feature ratings of 2, 4, and 5 are equally distributed."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Hypothesis 1: Food and beverage ratings 2, 4, 5 are equally distributed\n",
        "food_bev_ratings = airline_df[airline_df['food_bev'].isin([2, 4, 5])]['food_bev']\n",
        "observed_freq = food_bev_ratings.value_counts()\n",
        "expected_freq = len(food_bev_ratings) / 3  # Assuming equal chance for each rating\n",
        "chi2_stat, p_value = stats.chisquare(observed_freq, f_exp=expected_freq)\n",
        "\n",
        "print(\"\\nHypothesis 1:\")\n",
        "print(f\"Chi-square statistic: {chi2_stat}\")\n",
        "print(f\"P-value: {p_value}\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights:**\n",
        "\n",
        "The extremely low p-value suggests strong evidence against the null hypothesis, which assumes that the food and beverage ratings 2, 4, and 5 are equally distributed. Since the p-value is essentially zero, we have strong reason to reject the null hypothesis. This indicates that the distribution of food and beverage ratings 2, 4, and 5 is significantly different from what would be expected under the assumption of equal chances."
      ],
      "metadata": {
        "id": "FsXOE_X7tCKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the given code, the chi-square test is performed to obtain the p-value. The chi-square test is used to determine if there is a significant association between categorical variables. In this specific case, the chi-square test is used to test whether the observed frequencies of food and beverage ratings 2, 4, and 5 are significantly different from the expected frequencies (assuming an equal chance for each rating)."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I choose the chi-square test for Hypothesis 1 (\"The food and beverage ratings 2, 4, 5 are equally distributed\") because it is an appropriate test for analyzing the distribution of categorical data and assessing whether the observed frequencies significantly differ from the expected frequencies.\n",
        "\n",
        "In this case, we are dealing with categorical data (food and beverage ratings 2, 4, and 5) and want to determine if there is any significant difference in the distribution of these ratings. The chi-square test allows us to compare the observed frequencies of these ratings with the expected frequencies (assuming equal chances for each rating) and assess whether any deviations are statistically significant."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Null Hypothesis (H0): Passengers who travel in Business Class do not rate cabin service higher on average compared to passengers who travel in Economy Class.\n",
        "* Alternate Hypothesis (H1): Passengers who travel in Business Class rate cabin service higher on average compared to passengers who travel in Economy Class."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Hypothesis 2: Business Class passengers rate cabin service higher than Economy Class passengers\n",
        "business_class_ratings = airline_df[airline_df['cabin'] == 'Business Class']['cabin_service']\n",
        "economy_class_ratings = airline_df[airline_df['cabin'] == 'Economy Class']['cabin_service']\n",
        "t_stat, p_value = stats.ttest_ind(business_class_ratings, economy_class_ratings, equal_var=False)\n",
        "\n",
        "print(\"Hypothesis 2:\")\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights:**\n",
        "\n",
        "Based on the extremely small p-value, we can conclude that there is a statistically significant difference in cabin service ratings between Business Class and Economy Class passengers. In other words, the difference in the mean cabin service ratings is highly unlikely to have occurred by chance alone. Given the low p-value, we can reject the null hypothesis that there is no difference in cabin service ratings between the two classes. The evidence from the data suggests that Business Class passengers rate cabin service significantly higher on average compared to Economy Class passengers."
      ],
      "metadata": {
        "id": "s2TUfG09v67i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the given code, the independent two-sample t-test is done to obtain the p-value for Hypothesis 2.\n",
        "\n",
        "The two-sample t-test is used to compare the means of two independent groups to determine if there is a statistically significant difference between them. In this case, the t-test is used to compare the mean cabin service ratings of passengers in Business Class with those in Economy Class."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific statistical test chosen for Hypothesis 2, which compares the cabin service ratings of passengers in Business Class with those in Economy Class, is the independent two-sample t-test. Here's why this test was chosen:\n",
        "\n",
        "1. Type of Data: The data for cabin service ratings is continuous and numeric, making it suitable for a t-test.\n",
        "\n",
        "2. Comparison of Two Groups: The hypothesis involves comparing the means of two independent groups (Business Class and Economy Class passengers).\n",
        "\n",
        "3. Assumption of Normality: The t-test assumes that the data within each group follows a normal distribution. While this assumption should ideally be tested, if the sample sizes are sufficiently large, the t-test can still provide valid results even if the normality assumption is not perfectly met."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Null Hypothesis (H0): Passengers who travel for Solo Leisure do not tend to rate seat comfort higher on average compared to passengers who travel for Business purposes.\n",
        "* Alternate Hypothesis (H1): Passengers who travel for Solo Leisure tend to rate seat comfort higher on average compared to passengers who travel for Business purposes."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Hypothesis 3: Solo Leisure travelers rate seat comfort higher than Business travelers\n",
        "solo_leisure_ratings = airline_df[airline_df['traveller_type'] == 'Solo Leisure']['seat_comfort']\n",
        "business_travel_ratings = airline_df[airline_df['traveller_type'] == 'Business']['seat_comfort']\n",
        "t_stat, p_value = stats.ttest_ind(solo_leisure_ratings, business_travel_ratings, equal_var=False)\n",
        "\n",
        "print(\"\\nHypothesis 3:\")\n",
        "print(f\"T-statistic: {t_stat}\")\n",
        "print(f\"P-value: {p_value}\")"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insight:**\n",
        "\n",
        " Based on this output, we can infer that Solo Leisure travelers tend to rate seat comfort significantly higher on average compared to Business travelers. This implies that Solo Leisure travelers, who are likely traveling for personal and leisure purposes, find the seat comfort to be more satisfactory than Business travelers, who might prioritize work-related factors during their flights."
      ],
      "metadata": {
        "id": "FzAZkEIixtMM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the provided code for Hypothesis 3, the statistical test used to obtain the p-value is an independent two-sample t-test (also known as the Welch's t-test) for comparing the means of two groups. The specific function used from the SciPy library is `stats.ttest_ind()`.\n",
        "\n",
        "The independent two-sample t-test is suitable for comparing the means of two groups when the assumption of equal variances is not met. In this case, the equal_var=False argument is passed to the stats.ttest_ind() function, indicating that the variances of the two groups are not assumed to be equal."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's why this test was chosen:\n",
        "\n",
        "1. Type of Data: The data consists of two independent groups (Solo Leisure travelers and Business travelers), and we want to compare the means of a continuous variable (seat comfort ratings) between these two groups.\n",
        "\n",
        "2. Sample Size and Normality: The t-test is suitable when the sample sizes are relatively large (typically more than 30) and the distribution of the data is approximately normal. While t-tests are robust to moderate departures from normality, if the sample sizes are very large and the distributions are not extremely skewed, the t-test can still provide valid results.\n",
        "\n",
        "3. Assumption of Equal Variances: The assumption of equal variances between the two groups is not met. In this case, the use of the Welch's t-test is appropriate, as it does not assume equal variances and is more robust when variances differ between groups."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "'we have done handling to all missing in data wrangling as we need cleaned and organised data for our analysis'"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in handling missing value, the SimpleImputer class from the sklearn.impute module is used to replace missing values in numerical columns with the median of each column.\n",
        "\n",
        "\n",
        "Median Imputation: Median imputation involves replacing missing values with the median of the non-missing values in the same column. The median is the middle value of a dataset when it is sorted in ascending order. It is robust to outliers and can be a better measure of central tendency when data is skewed."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "# Identify numerical columns with potential outliers\n",
        "numerical_cols = airline_df.select_dtypes(include='number').columns\n",
        "\n",
        "# Set the z-score threshold for identifying outliers\n",
        "z_score_threshold = 3\n",
        "\n",
        "# Dictionary to store the percentage of outliers for each numerical column\n",
        "percentage_of_outliers = {}\n",
        "\n",
        "# Loop through each numerical column and calculate the percentage of outliers\n",
        "for col in numerical_cols:\n",
        "    col_mean = airline_df[col].mean()\n",
        "    col_std = airline_df[col].std()\n",
        "    z_scores = np.abs((airline_df[col] - col_mean) / col_std)\n",
        "    num_outliers = len(airline_df[z_scores > z_score_threshold])\n",
        "    percentage = (num_outliers / len(airline_df)) * 100\n",
        "    percentage_of_outliers[col] = percentage\n",
        "\n",
        "# Print the percentage of outliers for each numerical column\n",
        "for col, percentage in percentage_of_outliers.items():\n",
        "    print(f\"Percentage of outliers in {col}: {percentage:.2f}%\")\n"
      ],
      "metadata": {
        "id": "g10jcGJs2tsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no outliers in this dataset."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the categorical columns\n",
        "categorical_columns = airline_df.select_dtypes(include=[\"object\"]).columns.unique()\n",
        "\n",
        "# Print the categorical columns\n",
        "print(categorical_columns)\n"
      ],
      "metadata": {
        "id": "PdaCpri4xs9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here 'customer_review' contains textual data so we will handle it in textual data processing."
      ],
      "metadata": {
        "id": "Itm20zti2FO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "# Encoding for 'airline' using Target Encoding\n",
        "airline_target_encoding = airline_df.groupby('airline')['overall'].mean().to_dict()\n",
        "airline_df['airline'] = airline_df['airline'].map(airline_target_encoding)\n",
        "\n",
        "# Encoding for 'traveller_type' using label Encoding\n",
        "traveller_label_encoder= LabelEncoder()\n",
        "airline_df['traveller_type'] = traveller_label_encoder.fit_transform(airline_df['traveller_type'])\n",
        "\n",
        "# Encoding for 'cabin' using Label Encoding\n",
        "cabin_label_encoder= LabelEncoder()\n",
        "airline_df['cabin'] = traveller_label_encoder.fit_transform(airline_df['cabin'])\n",
        "\n",
        "# Encoding for 'recommended' using Label Encoding\n",
        "recommended_label_encoder = LabelEncoder()\n",
        "airline_df['recommended'] = recommended_label_encoder.fit_transform(airline_df['recommended'])\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the modified dataframe\n",
        "airline_df.head().T"
      ],
      "metadata": {
        "id": "dEUxzL9qDw4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the unique values in our categorical columns, here are some encoding techniques that we will consider for each column:\n",
        "\n",
        "**`airline:-`** Since the 'airline' column has many unique values, we use Target Encoding to capture the distribution of each airline's ratings.\n",
        "\n",
        "\n",
        "**`traveller_type:-`** Since 'traveller_type' has distinct categories without a clear ordinal relationship, label Encoding would be a good choice to create binary columns for each type.\n",
        "\n",
        "**`cabin:-`** 'cabin' has ordinal categories, so label Encoding might be appropriate if we want to preserve the ordinal relationship.\n",
        "\n",
        "**`recommended:-`** For binary categories like 'recommended', we will use Label Encoding where 'yes' maps to 1 and 'no' maps to 0.\n",
        "\n",
        "**`arrival_city`** and **`departure_city:-`** These columns have a large number of unique values but their importance is negligible so we dont use any encoding and drop them in feature selection."
      ],
      "metadata": {
        "id": "JMFq4p6C-kkR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our dataset, there is a feature 'customer_review' which contains textual data so we will convert that text review into numeric review so that we can use it in our feature selection as it would be very helpful to know which review is providing recommendation. For this whole process we use `NLP(NATURAL LANGUAGE PROCESSING)` for reviews."
      ],
      "metadata": {
        "id": "q8v1amurRXFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install vaderSentiment package\n",
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "id": "znGGtXYXbghb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing SentimentIntensityAnalyzer class for NLP\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "6MIVBB2PcN8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating function to get sentiment score for review\n",
        "def sentiment_scores(sentence):\n",
        "\n",
        "    # Create a SentimentIntensityAnalyzer object.\n",
        "    sid_obj = SentimentIntensityAnalyzer()\n",
        "\n",
        "    #scorring each reviews depending on their polarity\n",
        "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
        "\n",
        "    return  sentiment_dict['compound']"
      ],
      "metadata": {
        "id": "CuLkCeqWboTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating numeric review column to store polarity for each customer review\n",
        "airline_df['numeric_review'] = airline_df['customer_review'].apply(sentiment_scores)"
      ],
      "metadata": {
        "id": "OWBGN_jHbqUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "airline_df[['customer_review','numeric_review']].head(10)"
      ],
      "metadata": {
        "id": "Zj7b9JxgbsU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "airline_df.head().T"
      ],
      "metadata": {
        "id": "etBRoE-XgAFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "#drop unnecessary columns,which are not for our use\n",
        "airline_df = airline_df.drop(['author','review_date','date_flown','customer_review', 'month', 'flight_year','flight_month','arrival_city','departure_city'],axis=1)\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "\n",
        "# Separate the feature matrix 'X' and the target variable 'y'\n",
        "X = airline_df.drop(columns=['recommended'])\n",
        "y = airline_df['recommended']\n",
        "\n",
        "# Number of top features to select\n",
        "k = 10\n",
        "\n",
        "# Perform feature selection using ANOVA\n",
        "selector = SelectKBest(score_func=f_regression, k=k)\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "\n",
        "# Get the indices of the selected features\n",
        "selected_feature_indices = selector.get_support(indices=True)\n",
        "\n",
        "# Get the names of the selected features\n",
        "selected_feature_names = X.columns[selected_feature_indices]\n",
        "selected_feature_scores = selector.scores_[selected_feature_indices]\n",
        "# Now, 'X_selected' contains only the selected features, and 'selected_feature_names' contains their names.\n",
        "# Print the selected features and their corresponding ANOVA F-values\n",
        "print(\"Selected Features:\")\n",
        "for feature, score in zip(selected_feature_names, selected_feature_scores):\n",
        "    print(f\"{feature}: ANOVA F-value = {score}\")"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLAyu97xjPHB"
      },
      "source": [
        "In the code for feature selection in the merged dataset, we used the SelectKBest method with the ANOVA (Analysis of Variance) score function. Let's discuss the feature selection methods used and the reasons for choosing them:\n",
        "\n",
        "SelectKBest with ANOVA: SelectKBest is a feature selection method from scikit-learn that selects the top 'k' features based on univariate statistical tests. The ANOVA score function is used specifically for regression tasks (predicting continuous target variables) and evaluates the relationship between each feature and the target variable using ANOVA F-values.\n",
        "\n",
        "Reason for using SelectKBest with ANOVA: We chose this method because the target variable 'Sales' is a continuous numerical variable in the regression task. The ANOVA F-values help us assess the statistical significance of each feature's relationship with the target. By selecting the top 'k' features, we aim to keep the most informative features and reduce the model's complexity, which can help prevent overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the selected features along with a brief explanation of why they might be important:\n",
        "\n",
        "1. airline: The airline a passenger chooses can significantly influence their overall experience. Different airlines might have different levels of service, amenities, and customer satisfaction.\n",
        "\n",
        "2. overall: The overall rating of a passenger's experience is a direct measure of their satisfaction. This is likely one of the most important features in understanding how well an airline is performing.\n",
        "\n",
        "3. traveller_type: Different types of travelers (business, family leisure, solo leisure, couple leisure) might have varying expectations and preferences, leading to differences in ratings and satisfaction.\n",
        "\n",
        "4. seat_comfort: Passenger comfort is a crucial aspect of air travel. Higher comfort ratings are likely associated with better seating arrangements and amenities.\n",
        "\n",
        "5. cabin_service: The quality of cabin service, including in-flight service, cleanliness, and attentiveness of staff, can significantly impact passenger satisfaction.\n",
        "\n",
        "6. food_bev: Food and beverage quality are important factors for passenger comfort and satisfaction during the flight.\n",
        "\n",
        "7. entertainment: In-flight entertainment options can enhance the overall travel experience, influencing passenger ratings and recommendations.\n",
        "\n",
        "8. ground_service: The quality of ground services, such as check-in, boarding, and baggage handling, can shape a passenger's perception of the airline.\n",
        "\n",
        "9. value_for_money: Passengers often consider the value they receive in relation to the price they paid. Higher value for money ratings suggest passengers feel their expenses were justified.\n",
        "\n",
        "10. numeric_review: It's unclear what this feature represents without more context. However, if it's derived from the customer review text, it could capture additional sentiment or insights not captured by the other numeric features."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "'we dont have much big data here, so dont need any tranformation'"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "'no need for this'"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "not needed here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "# Split the data into train and test sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 0)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E452Da9KtmQe"
      },
      "source": [
        "The test_size parameter in the train_test_split function controls the proportion of the data that should be allocated to the testing set when splitting the dataset into training and testing sets. In the above code, test_size=0.2 is used, which means that 20% of the data will be allocated to the testing set, and the remaining 80% will be used for training.The commonly used splitting ratios are 80:20 (test_size=0.2) and 70:30 (test_size=0.3). These ratios strike a good balance between having enough data for training and obtaining a reliable evaluation on the testing set."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declaring a dataset for storing the evaluation metrics for each of the models\n",
        "column_names = [\"MODEL NAME\", \"ACCURACY\", \"RECALL\",\"PRECISION\",\"F1-SCORE\",\"ROC AUC SCORE\"]\n",
        "metrics_df = pd.DataFrame(columns = column_names)"
      ],
      "metadata": {
        "id": "AmMXRRHIq0C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating function for storing evaluation metrices\n",
        "def add_metrics_details(model_name,y_test,y_pred,df):\n",
        "  df = df.append({'MODEL NAME': model_name,\n",
        "                  'ACCURACY':accuracy_score(y_test, y_pred),\n",
        "                  'RECALL': recall_score(y_test, y_pred),\n",
        "                  'PRECISION':precision_score(y_test, y_pred),\n",
        "                  'F1-SCORE':f1_score(y_test, y_pred,)\n",
        "                  ,'ROC AUC SCORE':roc_auc_score(y_test, y_pred)\n",
        "                  }\n",
        "                  ,ignore_index=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "eMy7hB0mq11e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1: Logistic Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "log_reg = LogisticRegression(fit_intercept=True, max_iter=10000)\n",
        "# Fit the Algorithm\n",
        "log_reg.fit(X_train, y_train)\n",
        "# Predict on the model\n",
        "y_pred_logreg = log_reg.predict(X_test)\n",
        "score=log_reg.score(X_test,y_test)\n",
        "print(f'Logistic regression score : {score}')\n",
        "\n",
        "# After building the model we are comparing the actual and the predicted values in this code:\n",
        "data = pd.DataFrame({'Actual':y_test, 'Predicted':y_pred_logreg})\n",
        "data"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(metrics.classification_report(y_test,y_pred_logreg))\n",
        "cm = confusion_matrix(y_test,y_pred_logreg,labels=[1,0])\n",
        "\n",
        "print(f'\\nAccuracy score % of the model is {round(accuracy_score(y_test,y_pred_logreg)*100,2)}%\\n')\n",
        "sns.heatmap(cm, annot=True, fmt = \".1f\",cmap='icefire')\n",
        "plt.title('Confusion Matrix for Logistic Regeression')"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using function to add the result in metrics_df\n",
        "metrics_df=add_metrics_details(\"Logistic Regression\",y_test,y_pred_logreg,metrics_df)\n",
        "metrics_df"
      ],
      "metadata": {
        "id": "Hp5g6_aOtj4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "scores = cross_val_score(log_reg, X_train, y_train, cv=10)\n",
        "print(\"Cross-Validation Scores:\", scores)\n",
        "print(\"Mean CV Score:\", scores.mean())\n",
        "print(\"Max and Min CV Score:\",scores.min(),scores.max())\n",
        "\n",
        "\n",
        "# Define hyperparameters distribution\n",
        "param_dist = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Create RandomizedSearchCV object\n",
        "logreg_hyper = RandomizedSearchCV(log_reg, param_distributions=param_dist, n_iter=10, cv=10)\n",
        "\n",
        "# Fit the Algorithm\n",
        "logreg_hyper.fit(X_train, y_train)\n",
        "\n",
        "# Get best parameters and score\n",
        "best_params = logreg_hyper.best_params_\n",
        "best_score = logreg_hyper.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Score:\", best_score)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_logreg_hyper = logreg_hyper.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "# Get the best estimator from the grid search\n",
        "#best_estimator = random_search.best_estimator_\n",
        "\n",
        "# Predict on the test set using the best estimator\n",
        "#y_pred_best = best_estimator.predict(X_test)\n",
        "\n",
        "# Calculate accuracy score\n",
        "#accuracy = accuracy_score(y_test, y_pred_best)\n",
        "#print(\"Accuracy Score with Best Estimator:\", accuracy)\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(metrics.classification_report(y_test,y_pred_logreg_hyper))\n",
        "cm = confusion_matrix(y_test,y_pred_logreg_hyper,labels=[1,0])\n",
        "print(cm)\n",
        "print(f'\\nAccuracy score % of the model is {round(accuracy_score(y_test,y_pred_logreg_hyper)*100,2)}%\\n')"
      ],
      "metadata": {
        "id": "t_5jdSNyfb-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using function to add the result in metrics_df\n",
        "metrics_df=add_metrics_details(\"Logistic Regression With Tuning\",y_test,y_pred_logreg_hyper,metrics_df)\n",
        "metrics_df"
      ],
      "metadata": {
        "id": "F1QtZuqMgsPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyvLh4RcMROE"
      },
      "source": [
        "i have used here randomizedCV because of certain reason-\n",
        "* Faster Computation: RandomizedSearchCV samples a fixed number of hyperparameter combinations randomly, whereas GridSearchCV exhaustively searches through all possible combinations. As a result, RandomizedSearchCV is generally faster because it evaluates fewer parameter settings.\n",
        "\n",
        "* Flexibility: RandomizedSearchCV allows you to specify the number of iterations (n_iter) instead of specifying a specific grid of hyperparameter values. This makes it more flexible when you have a large hyperparameter space and want to explore a random subset of it.\n",
        "\n",
        "* Better Exploration: RandomizedSearchCV tends to explore a broader range of hyperparameter values. This can be beneficial when the best hyperparameters are not located on the grid points of the traditional grid search.\n",
        "\n",
        "* Resource-Efficient: When dealing with computationally expensive models and large datasets, RandomizedSearchCV can be more resource-efficient since it runs fewer iterations compared to GridSearchCV."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the hyperparameter tuning process didn't result in a significant improvement in accuracy compared to our initial logistic regression model. This could mean that the default hyperparameters were already well-suited for your dataset, or that other factors such as feature engineering, data preprocessing, or choosing a different model could have a greater impact on improving performance."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2: Decision Tree"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "dtc =DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Fit the Algorithm\n",
        "dtc.fit(X_train,y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_dtc = dtc.predict(X_test)\n",
        "\n",
        "score=dtc.score(X_test,y_test)\n",
        "print(f'Decision Tree score : {score}')\n",
        "\n",
        "# After building the model we are comparing the actual and the predicted values in this code:\n",
        "data1 = pd.DataFrame({'Actual':y_test, 'Predicted':y_pred_dtc})\n",
        "data1"
      ],
      "metadata": {
        "id": "iUeKvDobDTtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(metrics.classification_report(y_test,y_pred_dtc))\n",
        "cm = confusion_matrix(y_test,y_pred_dtc,labels=[1,0])\n",
        "print(f'\\nAccuracy score % of the model is {round(accuracy_score(y_test,y_pred_dtc)*100,2)}%\\n')\n",
        "sns.heatmap(cm, annot=True, fmt = \".1f\",cmap='icefire')\n",
        "plt.title('Confusion Matrix for Decision Tree')"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using function to add the result in metrics_df\n",
        "metrics_df=add_metrics_details(\"Decision Tree\",y_test,y_pred_dtc,metrics_df)\n",
        "metrics_df"
      ],
      "metadata": {
        "id": "7yA8PFxoqSOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "scores = cross_val_score(dtc, X_train, y_train, cv=5)\n",
        "print(\"Cross-Validation Scores:\", scores)\n",
        "print(\"Mean CV Score:\", scores.mean())\n",
        "print(\"Max and Min CV Score:\",scores.max(),scores.min())\n",
        "\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Create GridSearchCV object\n",
        "dtc_hyper = GridSearchCV(dtc, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the Algorithm\n",
        "dtc_hyper.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and score from the GridSearchCV\n",
        "best_params = dtc_hyper.best_params_\n",
        "best_score = dtc_hyper.best_score_\n",
        "\n",
        "print(f'Best Parameters: {best_params}')\n",
        "print(f'Best Score: {best_score:.4f}')\n",
        "# Predict on the model\n",
        "y_pred_dtc_hyper = dtc_hyper.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(metrics.classification_report(y_test,y_pred_dtc_hyper))\n",
        "cm = confusion_matrix(y_test,y_pred_dtc_hyper,labels=[1,0])\n",
        "print(cm)\n",
        "print(f'\\nAccuracy score % of the model is {round(accuracy_score(y_test,y_pred_dtc_hyper)*100,2)}%\\n')"
      ],
      "metadata": {
        "id": "fK9WcuxShdHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using function to add the result in metrics_df\n",
        "metrics_df=add_metrics_details(\"Decision Tree With Tuning\",y_test,y_pred_dtc_hyper,metrics_df)\n",
        "metrics_df"
      ],
      "metadata": {
        "id": "V1ZABRYpjJy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "here, I used GridSearchCV as the hyperparameter optimization technique. GridSearchCV is a technique that exhaustively searches through a manually specified subset of the hyperparameter space of a machine learning algorithm to find the best combination of hyperparameters that results in the highest performance based on a specified scoring metric.\n",
        "\n",
        "In this case, I used GridSearchCV to tune the hyperparameters of the DecisionTreeClassifier, specifically criterion, max_depth, min_samples_split, and min_samples_leaf. The reason for using GridSearchCV is that it systematically evaluates all possible combinations of these hyperparameters within the specified parameter grid. This allows us to find the best set of hyperparameters that optimize the performance of the model.\n",
        "\n",
        "By using GridSearchCV, we ensure that we're not relying on a single set of hyperparameters, which might be suboptimal for the given dataset. Instead, we explore a range of hyperparameter combinations and select the one that provides the best performance, as measured by the specified scoring metric (in this case, accuracy)."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The accuracy score improved from 94.19% to 95.78% after hyperparameter tuning.\n",
        "* The precision for class 1 improved from 0.93 to 0.96, indicating better identification of positive cases.\n",
        "* The recall for class 1 decreased slightly from 0.94 to 0.94.\n",
        "* The F1-score for class 1 improved from 0.93 to 0.95.\n",
        "Overall, the decision tree model with hyperparameter tuning shows improved performance, particularly in terms of accuracy and precision.\n",
        "\n",
        "However, there is a slight trade-off with recall for class 1. This suggests that the tuned model is better at correctly identifying positive cases while maintaining good overall accuracy."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3: K-Nearest Neighbour"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "k = 5  # Number of neighbors\n",
        "knn = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "# Fit the Algorithm\n",
        "knn.fit(X_train, y_train)\n",
        "# Predict on the model\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "score=knn.score(X_test,y_test)\n",
        "print(f'K-Nearest Neghbours score : {score}')\n",
        "\n",
        "# After building the model we are comparing the actual and the predicted values in this code:\n",
        "data = pd.DataFrame({'Actual':y_test, 'Predicted':y_pred_knn})\n",
        "data"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(metrics.classification_report(y_test,y_pred_knn))\n",
        "cm = confusion_matrix(y_test,y_pred_knn,labels=[1,0])\n",
        "\n",
        "print(f'\\nAccuracy score % of the model is {round(accuracy_score(y_test,y_pred_knn)*100,2)}%\\n')\n",
        "sns.heatmap(cm, annot=True, fmt = \".1f\",cmap='icefire')\n",
        "plt.title('Confusion Matrix for K-Nearest Neighbours')"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using function to add the result in metrics_df\n",
        "metrics_df=add_metrics_details(\"K-Nearest Neighbours\",y_test,y_pred_knn,metrics_df)\n",
        "metrics_df"
      ],
      "metadata": {
        "id": "MmvODR_S6pNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "# Perform 5-fold cross-validation\n",
        "scores = cross_val_score(knn, X_train, y_train, cv=5)\n",
        "print(\"Cross-Validation Scores:\", scores)\n",
        "print(\"Mean CV Score:\", scores.mean())\n",
        "print(\"Max and Min CV Score:\",scores.max(),scores.min())\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "param_grid = {\n",
        "    'n_neighbors':np.arange(1,9),  # Number of neighbors\n",
        "    'weights': ['uniform', 'distance'],  # Weighting method\n",
        "    'p': [1, 2]  # Distance metric (1: Manhattan, 2: Euclidean)\n",
        "}\n",
        "\n",
        "# Create GridSearchCV with 5-fold cross-validation\n",
        "knn_hyper = GridSearchCV(knn, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the Algorithm\n",
        "knn_hyper.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model from GridSearchCV\n",
        "best_model = knn_hyper.best_estimator_\n",
        "\n",
        "print(\"Best Parameters:\", knn_hyper.best_params_)\n",
        "print(\"Best Score:\", knn_hyper.best_score_)\n",
        "# Predict on the model\n",
        "y_pred_knn_hyper = best_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(metrics.classification_report(y_test,y_pred_knn_hyper))\n",
        "cm = confusion_matrix(y_test,y_pred_knn_hyper,labels=[1,0])\n",
        "print(cm)\n",
        "print(f'\\nAccuracy score % of the model is {round(accuracy_score(y_test,y_pred_knn_hyper)*100,2)}%\\n')"
      ],
      "metadata": {
        "id": "I2koyOPP9_XV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using function to add the result in metrics_df\n",
        "metrics_df=add_metrics_details(\"K-Nearest Neighbours With Tuning\",y_test,y_pred_knn_hyper,metrics_df)\n",
        "metrics_df"
      ],
      "metadata": {
        "id": "TNUur6k9-h_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the code provided above, I used GridSearchCV for hyperparameter optimization. GridSearchCV is a technique that performs an exhaustive search over a specified parameter grid to find the combination of hyperparameters that results in the best model performance.\n",
        "\n",
        "Here's why I used GridSearchCV in this context:\n",
        "\n",
        "1. Exhaustive Search: GridSearchCV systematically explores all possible combinations of hyperparameters defined in the param_grid. This ensures that we don't miss out on potential parameter values that could lead to improved model performance.\n",
        "\n",
        "2. Cross-Validation: GridSearchCV uses cross-validation to evaluate the performance of each parameter combination. Cross-validation helps in estimating how well the model will perform on unseen data. The cv parameter is set to 5, which means 5-fold cross-validation is performed.\n",
        "\n",
        "3. Best Parameters and Score: After performing the search, GridSearchCV returns the best combination of hyperparameters based on the performance metric (in this case, accuracy). It also provides the best score achieved by the model using those parameters. This helps in selecting the optimal hyperparameters for the model.\n",
        "\n",
        "4. Automated Tuning: GridSearchCV automates the process of hyperparameter tuning. It saves time and effort compared to manually trying out different parameter combinations.\n",
        "\n",
        "5. Generalization: By using cross-validation and testing on different folds of the data, GridSearchCV helps ensure that the chosen hyperparameters generalize well to new, unseen data."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems that the hyperparameter tuning has slightly improved the performance of the k-nearest neighbours model, as indicated by the increased values in accuracy, precision, and ROC AUC score, while maintaining a similar level of recall and F1-score.\n",
        "\n",
        "Overall, the hyperparameter tuning has resulted in a more balanced and accurate model, which can better predict both positive and negative classes. This improvement is particularly valuable for classification tasks where both classes have equal significance."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 4: Naïve Bayes Classifier"
      ],
      "metadata": {
        "id": "wz6dvG62lSJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 4 Implementation\n",
        "nbc = GaussianNB()\n",
        "\n",
        "# Fit the Algorithm\n",
        "nbc.fit(X_train, y_train)\n",
        "# Predict on the model\n",
        "y_pred_nbc = nbc.predict(X_test)\n",
        "score = nbc.score(X_test,y_test)\n",
        "print(f'Naïve Bayes Classifier Score : {score}')\n",
        "\n",
        "# After building the model we are comparing the actual and the predicted values in this code:\n",
        "data = pd.DataFrame({'Actual':y_test, 'Predicted':y_pred_nbc})\n",
        "data"
      ],
      "metadata": {
        "id": "c3lRg2txlSJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "iqYeVgh1lSJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(metrics.classification_report(y_test,y_pred_nbc))\n",
        "cm = confusion_matrix(y_test,y_pred_nbc,labels=[1,0])\n",
        "\n",
        "print(f'\\nAccuracy score % of the model is {round(accuracy_score(y_test,y_pred_nbc)*100,2)}%\\n')\n",
        "sns.heatmap(cm, annot=True, fmt = \".1f\",cmap='icefire')\n",
        "plt.title('Confusion Matrix for Naïve Bayes Classifier')"
      ],
      "metadata": {
        "id": "r9HAfyvmlSJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using function to add the result in metrics_df\n",
        "metrics_df=add_metrics_details(\"Naïve Bayes Classifier\",y_test,y_pred_nbc,metrics_df)\n",
        "metrics_df"
      ],
      "metadata": {
        "id": "jkqvk2w4lSJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "S9OmyMoblSJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 4 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "# Perform 5-fold cross-validation\n",
        "scores = cross_val_score(nbc, X_train, y_train, cv=5)\n",
        "print(\"Cross-Validation Scores:\", scores)\n",
        "print(\"Mean CV Score:\", scores.mean())\n",
        "print(\"Max and Min CV Score:\",scores.max(),scores.min())\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "param_grid = {\n",
        "   \"var_smoothing\": np.logspace(-9, -1, 10)\n",
        "}\n",
        "\n",
        "# Create GridSearchCV with 5-fold cross-validation\n",
        "nbc_hyper = GridSearchCV(estimator=nbc, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Fit the Algorithm\n",
        "nbc_hyper.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model from GridSearchCV\n",
        "best_model = nbc_hyper.best_estimator_\n",
        "\n",
        "print(\"Best Parameters:\", nbc_hyper.best_params_)\n",
        "print(\"Best Score:\", nbc_hyper.best_score_)\n",
        "# Predict on the model\n",
        "y_pred_nbc_hyper = best_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "BjNQ3MYIlSJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(metrics.classification_report(y_test,y_pred_nbc_hyper))\n",
        "cm = confusion_matrix(y_test,y_pred_nbc_hyper,labels=[1,0])\n",
        "print(cm)\n",
        "print(f'\\nAccuracy score % of the model is {round(accuracy_score(y_test,y_pred_nbc_hyper)*100,2)}%\\n')"
      ],
      "metadata": {
        "id": "TWE6q5y4lSJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using function to add the result in metrics_df\n",
        "metrics_df=add_metrics_details(\" Naïve Bayes Classifier With Tuning\",y_test,y_pred_nbc_hyper,metrics_df)\n",
        "metrics_df"
      ],
      "metadata": {
        "id": "f1rSRLGllSJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "e6OpR3aylSJ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In the code we provided above for hyperparameter tuning of the Naïve Bayes Classifier, we used GridSearchCV. GridSearchCV is a widely used hyperparameter optimization technique that exhaustively searches through a predefined set of hyperparameter values to find the combination that gives the best performance.\n",
        "\n",
        "* GridSearchCV is a good choice for hyperparameter tuning because it systematically explores a range of hyperparameter values and evaluates their impact on the model's performance using cross-validation. It helps us to find the optimal hyperparameters that lead to the best generalization on unseen data.\n",
        "\n",
        "* By using GridSearchCV, we ensure that we're not relying on intuition or guesswork to select hyperparameters. Instead, we're allowing the algorithm to explore different combinations and identify the one that maximizes the chosen evaluation metric, such as accuracy, precision, recall, etc."
      ],
      "metadata": {
        "id": "0OAslBkGlSJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "4nL01t96lSKA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the comparison, we can see that there is a slight improvement in most of the evaluation metric scores after hyperparameter tuning. The accuracy, recall, and ROC AUC score have improved, while the precision has decreased slightly. Overall, the model's performance has improved slightly after hyperparameter tuning.\n",
        "\n",
        "Overall, the hyperparameter tuning has resulted in a more balanced and accurate model, which can better predict both positive and negative classes. This improvement is particularly valuable for classification tasks where both classes have equal significance."
      ],
      "metadata": {
        "id": "a61uTAs5lSKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 5: Support Vector Machine"
      ],
      "metadata": {
        "id": "6zhf4ZkB1_OX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 5 Implementation\n",
        "from sklearn.svm import SVC\n",
        "svm = SVC(kernel='linear')\n",
        "\n",
        "# Fit the Algorithm\n",
        "svm.fit(X_train, y_train)\n",
        "# Predict on the model\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "score = svm.score(X_test,y_test)\n",
        "print(f'Support Vector Machine Score : {score}')\n",
        "\n",
        "# After building the model we are comparing the actual and the predicted values in this code:\n",
        "data = pd.DataFrame({'Actual':y_test, 'Predicted':y_pred_svm})\n",
        "data"
      ],
      "metadata": {
        "id": "ypAkhiOe1_OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "eyCCQTwC1_Oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(metrics.classification_report(y_test,y_pred_svm))\n",
        "cm = confusion_matrix(y_test,y_pred_svm,labels=[1,0])\n",
        "\n",
        "print(f'\\nAccuracy score % of the model is {round(accuracy_score(y_test,y_pred_svm)*100,2)}%\\n')\n",
        "sns.heatmap(cm, annot=True, fmt = \".1f\",cmap='icefire')\n",
        "plt.title('Confusion Matrix for Support Vector Machine')"
      ],
      "metadata": {
        "id": "RlVjmysh1_Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using function to add the result in metrics_df\n",
        "metrics_df=add_metrics_details(\"Support Vector Machine\",y_test,y_pred_svm,metrics_df)\n",
        "metrics_df"
      ],
      "metadata": {
        "id": "RjL4mgGq1_Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "jZpWCpjh1_Od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 5 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "# Perform 5-fold cross-validation\n",
        "scores = cross_val_score(svm, X_train, y_train, cv=5)\n",
        "print(\"Cross-Validation Scores:\", scores)\n",
        "print(\"Mean CV Score:\", scores.mean())\n",
        "print(\"Max and Min CV Score:\",scores.max(),scores.min())\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "param_grid = {\n",
        "   'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': [0.1, 1, 'scale', 'auto']\n",
        "}\n",
        "\n",
        "# Create GridSearchCV with 5-fold cross-validation\n",
        "svm_hyper = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the Algorithm\n",
        "svm_hyper.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model from GridSearchCV\n",
        "best_model = svm_hyper.best_estimator_\n",
        "\n",
        "print(\"Best Parameters:\", svm_hyper.best_params_)\n",
        "print(\"Best Score:\", svm_hyper.best_score_)\n",
        "# Predict on the model\n",
        "y_pred_svm_hyper = best_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "x7OtZEoN1_Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print(metrics.classification_report(y_test,y_pred_svm_hyper))\n",
        "cm = confusion_matrix(y_test,y_pred_svm_hyper,labels=[1,0])\n",
        "print(cm)\n",
        "print(f'\\nAccuracy score % of the model is {round(accuracy_score(y_test,y_pred_svm_hyper)*100,2)}%\\n')"
      ],
      "metadata": {
        "id": "P9H3MuMd1_Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using function to add the result in metrics_df\n",
        "metrics_df=add_metrics_details(\" Support Vector Machine With Tuning\",y_test,y_pred_svm_hyper,metrics_df)\n",
        "metrics_df"
      ],
      "metadata": {
        "id": "pDRBmTz81_Og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "zjkIOGzd1_Oh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In the code we provided above for hyperparameter tuning of the Naïve Bayes Classifier, we used GridSearchCV. GridSearchCV is a widely used hyperparameter optimization technique that exhaustively searches through a predefined set of hyperparameter values to find the combination that gives the best performance.\n",
        "\n",
        "* GridSearchCV is a good choice for hyperparameter tuning because it systematically explores a range of hyperparameter values and evaluates their impact on the model's performance using cross-validation. It helps us to find the optimal hyperparameters that lead to the best generalization on unseen data.\n",
        "\n",
        "* By using GridSearchCV, we ensure that we're not relying on intuition or guesswork to select hyperparameters. Instead, we're allowing the algorithm to explore different combinations and identify the one that maximizes the chosen evaluation metric, such as accuracy, precision, recall, etc."
      ],
      "metadata": {
        "id": "SeARyhcf1_Oh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "3Nl7Eb7T1_Oi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the comparison, we can see that there is a slight improvement in most of the evaluation metric scores after hyperparameter tuning. The accuracy, recall, and ROC AUC score have improved, while the precision has decreased slightly. Overall, the model's performance has improved slightly after hyperparameter tuning.\n",
        "\n",
        "Overall, the hyperparameter tuning has resulted in a more balanced and accurate model, which can better predict both positive and negative classes. This improvement is particularly valuable for classification tasks where both classes have equal significance."
      ],
      "metadata": {
        "id": "6XXKLaZb1_Oj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}